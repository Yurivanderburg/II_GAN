\section{Past Efforts at Image Reconstruction relevant to Intensity Interferometry}
\textbf{Several approaches have been developed for phase reconstruction in intensity interferometry (II). \cite{gamo1963triple} introduced triple-intensity correlation, applied by \cite{goldberger1963use} to microscopic systems and extended by \cite{sato1978imaging, sato1979computer, sato1981adaptive} to measure stellar diameters and phases, though limited by low signal-to-noise ratio (SNR). \cite{GerchbergSaxton1972} proposed an iterative phase retrieval method using image and diffraction plane data, sensitive to initial estimates and convergence speed. \cite{Fienup1982} improved this with the Hybrid Input-Output algorithm, enhancing robustness in noisy conditions. \cite{holmes2010two} utilized Cauchy-Riemann relations for 1-D and 2-D image reconstruction, applied to simulated stellar data with Imaging Cherenkov Telescope Arrays \citep{nunez2010stellar, nunez2012high, nunez2012imaging}, but faced computational complexity for higher dimensions. \cite{Li2014} introduced a regularized iterative method incorporating priors (e.g., sparsity) to mitigate noise and ill-posedness, though challenged by parameter tuning and initial guess sensitivity. The Transport-of-Intensity Equation (TIE), proposed by \cite{Teague1983}, retrieves phase from intensity variations across planes; \cite{Zhang2020} solved TIE as a Poisson equation using a maximum intensity assumption, while \cite{Kirisits2024} combined TIE with the Transport of Phase Equation for improved accuracy across arbitrary apertures and non-uniform illumination, with convergence dependent on initial guesses and boundary conditions.}

With non-linearity built into their architecture, artificial neural networks (ANNs) empowered by deep learning methods are promising for exploring the task of reconstructing images of stellar objects from ground-based observations. Convolutional Neural Networks (CNNs), with their specialized architecture for processing two-dimensional datasets, are a natural choice for image processing tasks. In astronomical image reconstruction projects, a common challenge is that the interferometric data are typically undersampled as well as noisy.  Therefore, the CNN architectures and deep learning methods employed must be capable of reliably learning both the global context of the training dataset and the local features within it. Among the various CNN architectures, U-Net models \citep{ronneberger2015u} have proven successful in such tasks.

Furthermore, given that achieving a high signal-to-noise ratio (SNR) is often challenging in astronomical datasets, it is immensely beneficial if additional data can be generated using the available information from the observed sky density distribution and ground-based observations (II data, in our case) of the sources under investigation. Generative Adversarial Networks (GANs), introduced by \cite{goodfellow2014generative}, have been successful in such data augmentation tasks. Conditional GAN (cGAN) architectures, proposed by \cite{mirza2014conditional} and applied to a wide variety of datasets by \cite{isola2017image}, leverage additional information about the images in the training datasets and have demonstrated remarkable robustness in image recovery across diverse data types.

In the astrophysical context, \cite{schawinski2017galaxypics} employed a GAN model to recover features, such as spiral arms, central bulges, and disk structures of galaxies, from noise-affected images. \cite{mustafa2019cosmogan} developed and customized a Deep Convolutional GAN, dubbed \textquotedblleft CosmoGAN\textquotedblright, capable of generating high-fidelity weak-lensing convergence maps of dark matter distribution that statistically reproduce real weak lensing structures. \cite{coccomini2021lightweightgan} have successfully generated credible images of planets, nebulae, and galaxies using \textquotedblleft lightweight\textquotedblright\ and \textquotedblleft physics-uninformed\textquotedblright\ GANs to produce synthetic images of celestial bodies. They also generated a \textquotedblleft Hubble Deep Field-inspired\textquotedblright\ wide-view simulation of the universe. 

