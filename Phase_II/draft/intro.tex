\section{Introduction}

Intensity Interferometry (II) was first reported by Hanbury Brown and Twiss (HBT) during the 1950s \citep{brown1954lxxiv, HBT56} as a \textquotedblleft new type of interferometry\textquotedblright\ to measure stellar parameters such as angular diameter, orbits, and limb darkening coefficients. Later, theoretical results reported by \cite{brown1957interferometry, brown1958interferometry}, along with those of \cite{glauber1963quantum} and \cite{MandelWolf1995, Hecht2002}, demonstrated the deeper physical properties of photon correlations that lie at the core of II and laid the foundation for Quantum Optics.

By the 1970s, with stellar parameter measurements of 32 stars in single and multiple star systems conducted by Hanbury Brown and his collaborators \citep{hanbury1974angular} at the historic Narrabri Stellar Intensity Interferometer (NSII) in Australia, II had emerged as an alternative technique for measuring stellar parameters. Despite these significant achievements, the method did not gain widespread adoption in the ensuing decades, primarily due to the unavailability of sensitive photon detectors and advanced data analysis equipment.

However, subsequent advancements in computational methods and modern electronics—which now provide detectors with time resolutions in the nanosecond (ns) to picosecond (ps) range—have revived II as a feasible technique for resolving astrophysical objects at visible wavelengths. Recent advancements in photon detectors show that II could be effective in achieving high-precision measurements of parameters for stellar objects \citep{10.1093/mnras/stab2391, 10.1093/mnras/stac2433}.

Beyond measuring the physical parameters of star systems, a fundamental goal of optical astronomy is to determine the sky intensity distribution of a source from ground-based observations. In the context of II, this involves reconstructing the source's image from the intensity correlations recorded by pairs of telescopes (light buckets) on the ground. However, because the primary observable in II is the electromagnetic field intensity rather than the field strength, a significant drawback of this method is the loss of phase information. Since a complete reconstruction of a source's brightness distribution requires phase information, the challenge is to recover the phase of the signal.


Several theoretical and computational approaches for phase reconstruction with II have been proposed. \cite{gamo1963triple} introduced the concept of triple-intensity correlation, which Goldberger subsequently applied \cite{goldberger1963use} in an experiment to observe scattered particles in microscopic systems. Sato conducted experiments to measure the diameter and phase of asymmetrical objects, suggesting that triple correlation could extend II to image stellar bodies \citep{sato1978imaging, sato1979computer, sato1981adaptive}. However, achieving a satisfactory signal-to-noise ratio (SNR) remained a significant challenge for this approach.

Gerchberg and Saxton suggested an iterative method \citep{GerchbergSaxton1972} to determine the phase from the image and diffraction plane pictures. This method relies on accurate initial estimates and may struggle with slow convergence otherwise. Fienup \citep{Fienup1982} introduced a Hybrid Input-Output algorithm that incorporates feedback mechanisms to improve convergence rate and robustness, particularly in noisy environments.

Later, \cite{holmes2010two} proposed an alternative method that utilizes the Cauchy-Riemann relations to reconstruct 1-D images and extends the approach to 2-D images across a range of signal-to-noise (SNR) values. This algorithm was applied to simulated data of stellar objects using II, considering both existing and forthcoming Imaging Cherenkov Telescope Arrays (IACTs) with a large number of telescopes \citep{nunez2010stellar, nunez2012high, nunez2012imaging}. However, this method faces challenges related to computational complexity when attempting to generalize to higher dimensions.

Li et al. suggested a flexible iterative Regularization method \citep{Li2014} that incorporates prior information (e.g., sparsity, smoothness, or non-negativity) to reduce the ill-posedness of the phase retrieval problem. This method is more robust against noise and stabilizes the solution against artefacts and spurious solutions. Nevertheless, it faces challenges regarding the choice of the regularization parameter, computational complexity, and sensitivity to the initial guess.

The Transport-of-Intensity Equation (TIE) method is a non-interferometric technique first proposed by Teague \citep{Teague1983} that relates the intensity variations along the optical axis to the phase of the optical fields. This method enables phase retrieval from intensity measurements taken at multiple planes. Zhang et al. \citep{Zhang2020} proposed a method to obtain a \textquotedblleft universal solution\textquotedblright\ to the TIE by employing a \textquotedblleft maximum intensity assumption\textquotedblright, thereby converting the TIE into a Poisson equation which is then solved iteratively. More recently, Kirisits et al. \citep{Kirisits2024} explored hybrid methods that combine the TIE with other equations, such as the Transport of Phase Equation (TPE). These approaches leverage the strengths of both equations to improve phase retrieval accuracy. This method is universally applicable, as it works for arbitrarily shaped apertures, handles non-uniform illumination, and accommodates inhomogeneous boundary conditions. It guarantees convergence, although the speed of convergence depends on the quality of the initial guess, and the final results are influenced by the boundary conditions.

\textcolor{magenta}{With non-linearity built into their architecture, artificial neural networks (ANNs) empowered by deep learning methods have become an obvious choice for exploring the task of reconstructing images of stellar objects from ground-based observations. Convolutional Neural Networks (CNNs), with their specialized architecture for processing two-dimensional datasets, are a natural choice for image processing tasks. In astronomical image reconstruction projects, a common challenge is that the ground-truth data are often noisy, incomplete, or both. Therefore, the CNN architectures and deep learning methods employed must be capable of reliably learning both the global context of the training dataset and the local features within it. Among the various CNN architectures, U-Net models \citep{ronneberger2015u} have proven successful in such tasks.}

\textcolor{magenta}{Furthermore, given that achieving a high signal-to-noise ratio (SNR) is often challenging in astronomical datasets, it is immensely beneficial if additional data can be generated using the available information from the observed sky density distribution and ground-based observations (II data, in our case) of the sources under investigation. Generative Adversarial Networks (GANs), introduced by Ian Goodfellow et al. \citep{goodfellow2014generative}, have been successful in data augmentation tasks. Conditional GAN (cGAN) architectures, proposed by Mirza \& Osindero \citep{mirza2014conditional} and applied to a wide variety of datasets by Isola et al. \citep{isola2017image}, leverage additional information about the images in the training datasets and have demonstrated remarkable robustness in image recovery across diverse data types.}

\textcolor{magenta}{In the astrophysical context, Schawinski et al. \cite{schawinski2017galaxypics} employed a cGAN model to recover features—such as spiral arms, central bulges, and disk structures—of galaxies from noise-affected images. Mustafa et al. \citep{mustafa2019cosmogan} developed and customized a Deep Convolutional GAN, dubbed \textquotedblleft CosmoGAN\textquotedblright, capable of generating high-fidelity weak-lensing convergence maps of the dark matter distribution that statistically reproduce real weak lensing structures. Coccomini et al. \citep{coccomini2021lightweightgan} have successfully generated credible images of planets, nebulae, and galaxies using \textquotedblleft lightweight\textquotedblright\ and \textquotedblleft physics-uninformed\textquotedblright\ GANs to produce synthetic images of celestial bodies. They also generated a \textquotedblleft Hubble Deep Field-inspired\textquotedblright\ wide-view simulation of the universe. 
}

In this paper, we propose a conditional Generative Adversarial Network (cGAN) model \citep{isola2017image} to reconstruct images of fast-rotating stars using their simulated Intensity Interferograms and simulated sky-intensity distributions as input data for training, testing, and validation. We consider four Imaging Cherenkov Telescope Arrays (IACTs) located in the Northern Hemisphere and perform a one-night simulation of a fast-rotating star. The image predicted by the trained GAN shows promising results in reconstructing the star’s shape and size. The evaluation, conducted using image moments, demonstrates that the size and shape are successfully recovered, although the brightness distribution is reconstructed only at the third-order moment.

This paper is organized as follows. The first section discusses Intensity Interferometry, focusing on its signal and noise characteristics for fast-rotating stars along the Earth’s rotation. The second section introduces the GAN formulation and its structure. The third section details the parameter selection for training the GAN for image reconstruction. The fourth section presents the results of the trained GAN both visually and via image moments. Finally, the paper concludes with a discussion of the overall results.